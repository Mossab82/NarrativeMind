    # Training loop
    model.train()
    train_loss = 0
    
    for batch in tqdm(train_loader, desc='Training'):
        optimizer.zero_grad()
        
        # Forward pass
        outputs = model(
            input_ids=batch['input_ids'].to(device),
            attention_mask=batch['attention_mask'].to(device),
            labels=batch['input_ids'].to(device)
        )
        
        loss = outputs.loss
        train_loss += loss.item()
        
        # Backward pass
        loss.backward()
        optimizer.step()
        
    avg_train_loss = train_loss / len(train_loader)
    
    # Validation
    model.eval()
    val_loss = 0
    val_metrics = []
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc='Validation'):
            # Validation step
            outputs = model(
                input_ids=batch['input_ids'].to(device),
                attention_mask=batch['attention_mask'].to(device),
                labels=batch['input_ids'].to(device)
            )
            
            val_loss += outputs.loss.item()
            
            # Generate and evaluate sample
            if batch.get('dialect'):
                text = model.generate_story(
                    model.tokenizer.decode(batch['input_ids'][0]),
                    target_dialect=batch['dialect'][0]
                )
                metrics = evaluator.evaluate(text)
                val_metrics.append(metrics)
    
    # Print metrics
    print(f"Train Loss: {avg_train_loss:.4f}")
    print(f"Validation Loss: {val_loss/len(val_loader):.4f}")
    
    if val_metrics:
        print("\nValidation Metrics:")
        avg_metrics = {k: np.mean([m[k] for m in val_metrics]) 
                      for k in val_metrics[0].keys()}
        for k, v in avg_metrics.items():
            print(f"{k}: {v:.4f}")
