{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NarrativeMind: Results Analysis\n",
    "\n",
    "This notebook analyzes and visualizes the results from the NarrativeMind experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from narrative_mind.utils import Visualizer\n",
    "from narrative_mind.evaluation import NarrativeEvaluator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load test results\n",
    "with open('results/test_results.json') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Create DataFrame of metrics\n",
    "metrics_df = pd.DataFrame([s['metrics'] for s in results['generated_samples']])\n",
    "print(\"\\nMetrics Summary:\")\n",
    "print(metrics_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze BLEU Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot BLEU score distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(metrics_df['bleu'], bins=30)\n",
    "plt.axvline(x=29.8, color='r', linestyle='--', label='Paper Result (29.8)')\n",
    "plt.title('Distribution of BLEU Scores')\n",
    "plt.xlabel('BLEU Score')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean BLEU Score: {metrics_df['bleu'].mean():.2f} ± {metrics_df['bleu'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Cultural Preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot cultural preservation metrics\n",
    "cultural_metrics = ['pattern_f1', 'cultural_elements_score', 'cultural_preservation']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics_df[cultural_metrics].boxplot()\n",
    "plt.axhline(y=0.752, color='r', linestyle='--', label='Paper Result (75.2%)')\n",
    "plt.title('Cultural Preservation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCultural Preservation Metrics:\")\n",
    "for metric in cultural_metrics:\n",
    "    mean = metrics_df[metric].mean()\n",
    "    std = metrics_df[metric].std()\n",
    "    print(f\"{metric}: {mean:.3f} ± {std:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Dialect Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot dialect accuracy by dialect\n",
    "dialect_metrics = pd.DataFrame([\n",
    "    {\n",
    "        'dialect': s.get('dialect'),\n",
    "        'accuracy': s['metrics']['dialect_accuracy'],\n",
    "        'confidence': s['metrics']['dialect_confidence']\n",
    "    }\n",
    "    for s in results['generated_samples'] if s.get('dialect')\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=dialect_metrics, x='dialect', y='accuracy')\n",
    "plt.axhline(y=0.72, color='r', linestyle='--', label='Paper Result (κ=0.72)')\n",
    "plt.title('Dialect Accuracy by Dialect')\n",
    "plt.xlabel('Dialect')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDialect Accuracy by Dialect:\")\n",
    "print(dialect_metrics.groupby('dialect')['accuracy'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Generated Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze story characteristics\n",
    "story_lengths = [len(s['generated_text'].split()) for s in results['generated_samples']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(story_lengths, bins=30)\n",
    "plt.title('Distribution of Generated Story Lengths')\n",
    "plt.xlabel('Length (words)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage story length: {np.mean(story_lengths):.1f} ± {np.std(story_lengths):.1f} words\")\n",
    "\n",
    "# Display sample stories with high metrics\n",
    "print(\"\\nExample High-Quality Generations:\")\n",
    "top_stories = sorted(\n",
    "    results['generated_samples'],\n",
    "    key=lambda x: x['metrics']['cultural_preservation'],\n",
    "    reverse=True\n",
    ")[:3]\n",
    "\n",
    "for i, story in enumerate(top_stories, 1):\n",
    "    print(f\"\\nStory {i}:\")\n",
    "    print(f\"Text: {story['generated_text']}\")\n",
    "    print(\"\\nMetrics:\")\n",
    "    for k, v in story['metrics'].items():\n",
    "        print(f\"{k}: {v:.3f}\")"
   ]
  }
 ]
}
